{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a11c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the required packages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5d24a70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>A_network_feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>B_following_count</th>\n",
       "      <th>B_listed_count</th>\n",
       "      <th>B_mentions_received</th>\n",
       "      <th>B_retweets_received</th>\n",
       "      <th>B_mentions_sent</th>\n",
       "      <th>B_retweets_sent</th>\n",
       "      <th>B_posts</th>\n",
       "      <th>B_network_feature_1</th>\n",
       "      <th>B_network_feature_2</th>\n",
       "      <th>B_network_feature_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614689</td>\n",
       "      <td>400</td>\n",
       "      <td>5729</td>\n",
       "      <td>199.618296</td>\n",
       "      <td>67.812469</td>\n",
       "      <td>9.366192</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>4.094488</td>\n",
       "      <td>669</td>\n",
       "      <td>39.193741</td>\n",
       "      <td>...</td>\n",
       "      <td>563</td>\n",
       "      <td>20057</td>\n",
       "      <td>967.720642</td>\n",
       "      <td>579.431128</td>\n",
       "      <td>4.473798</td>\n",
       "      <td>0.805680</td>\n",
       "      <td>6.241806</td>\n",
       "      <td>4027</td>\n",
       "      <td>57.643839</td>\n",
       "      <td>3201.293706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>739581</td>\n",
       "      <td>10723</td>\n",
       "      <td>1279</td>\n",
       "      <td>102.026750</td>\n",
       "      <td>96.771319</td>\n",
       "      <td>1.537322</td>\n",
       "      <td>1.054358</td>\n",
       "      <td>3.467754</td>\n",
       "      <td>432</td>\n",
       "      <td>11.191686</td>\n",
       "      <td>...</td>\n",
       "      <td>12949</td>\n",
       "      <td>1311</td>\n",
       "      <td>38.260522</td>\n",
       "      <td>10.697567</td>\n",
       "      <td>12.845793</td>\n",
       "      <td>1.584284</td>\n",
       "      <td>12.106662</td>\n",
       "      <td>144</td>\n",
       "      <td>209.717241</td>\n",
       "      <td>21496.565517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3638</td>\n",
       "      <td>3341</td>\n",
       "      <td>85</td>\n",
       "      <td>2.793577</td>\n",
       "      <td>1.402703</td>\n",
       "      <td>2.594089</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>3.802143</td>\n",
       "      <td>11</td>\n",
       "      <td>9.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>320</td>\n",
       "      <td>3673</td>\n",
       "      <td>1207.190077</td>\n",
       "      <td>599.721600</td>\n",
       "      <td>0.842022</td>\n",
       "      <td>0.593199</td>\n",
       "      <td>7.044735</td>\n",
       "      <td>3918</td>\n",
       "      <td>7.859818</td>\n",
       "      <td>637.983300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>613</td>\n",
       "      <td>1259</td>\n",
       "      <td>31</td>\n",
       "      <td>1.326041</td>\n",
       "      <td>0.356943</td>\n",
       "      <td>6.249678</td>\n",
       "      <td>2.323064</td>\n",
       "      <td>7.488116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3599</td>\n",
       "      <td>1072</td>\n",
       "      <td>10.300222</td>\n",
       "      <td>3.828561</td>\n",
       "      <td>1.624092</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.614287</td>\n",
       "      <td>43</td>\n",
       "      <td>113.840909</td>\n",
       "      <td>2537.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1352348</td>\n",
       "      <td>331</td>\n",
       "      <td>15647</td>\n",
       "      <td>19129.848662</td>\n",
       "      <td>14552.733991</td>\n",
       "      <td>2.065418</td>\n",
       "      <td>0.580955</td>\n",
       "      <td>16.281502</td>\n",
       "      <td>52580</td>\n",
       "      <td>3.092448</td>\n",
       "      <td>...</td>\n",
       "      <td>147521</td>\n",
       "      <td>15043</td>\n",
       "      <td>9902.070379</td>\n",
       "      <td>5012.055876</td>\n",
       "      <td>10.438460</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>193.072418</td>\n",
       "      <td>28564</td>\n",
       "      <td>10.964144</td>\n",
       "      <td>1035.955493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>614689</td>\n",
       "      <td>400</td>\n",
       "      <td>5729</td>\n",
       "      <td>199.618296</td>\n",
       "      <td>67.812469</td>\n",
       "      <td>9.366192</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>4.094488</td>\n",
       "      <td>669</td>\n",
       "      <td>39.193741</td>\n",
       "      <td>...</td>\n",
       "      <td>550744</td>\n",
       "      <td>20006</td>\n",
       "      <td>936.636126</td>\n",
       "      <td>206.101772</td>\n",
       "      <td>41.317189</td>\n",
       "      <td>0.595962</td>\n",
       "      <td>42.813704</td>\n",
       "      <td>3691</td>\n",
       "      <td>69.150872</td>\n",
       "      <td>3456.096107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>3764</td>\n",
       "      <td>703</td>\n",
       "      <td>222</td>\n",
       "      <td>5.270621</td>\n",
       "      <td>1.601159</td>\n",
       "      <td>2.338333</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.596539</td>\n",
       "      <td>18</td>\n",
       "      <td>139.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>3557</td>\n",
       "      <td>9</td>\n",
       "      <td>0.751434</td>\n",
       "      <td>0.295998</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>3</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>218.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>1611042</td>\n",
       "      <td>936</td>\n",
       "      <td>10346</td>\n",
       "      <td>388.093282</td>\n",
       "      <td>65.719046</td>\n",
       "      <td>2.086961</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>1.096322</td>\n",
       "      <td>1637</td>\n",
       "      <td>35.500603</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>13838</td>\n",
       "      <td>133.213345</td>\n",
       "      <td>56.027747</td>\n",
       "      <td>2.622550</td>\n",
       "      <td>1.121160</td>\n",
       "      <td>2.622550</td>\n",
       "      <td>562</td>\n",
       "      <td>135.158451</td>\n",
       "      <td>5187.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>631958</td>\n",
       "      <td>674</td>\n",
       "      <td>7522</td>\n",
       "      <td>614.968745</td>\n",
       "      <td>329.330091</td>\n",
       "      <td>4.052279</td>\n",
       "      <td>1.340566</td>\n",
       "      <td>12.305035</td>\n",
       "      <td>2536</td>\n",
       "      <td>35.838659</td>\n",
       "      <td>...</td>\n",
       "      <td>2799</td>\n",
       "      <td>7371</td>\n",
       "      <td>296.978205</td>\n",
       "      <td>135.831429</td>\n",
       "      <td>15.033026</td>\n",
       "      <td>4.807180</td>\n",
       "      <td>8.262063</td>\n",
       "      <td>1201</td>\n",
       "      <td>87.183775</td>\n",
       "      <td>3547.782285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>2307845</td>\n",
       "      <td>329</td>\n",
       "      <td>12580</td>\n",
       "      <td>530.084862</td>\n",
       "      <td>189.947739</td>\n",
       "      <td>4.827720</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>3.130447</td>\n",
       "      <td>2164</td>\n",
       "      <td>80.914768</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>39725</td>\n",
       "      <td>1404.436304</td>\n",
       "      <td>431.103945</td>\n",
       "      <td>2.596749</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>5.559490</td>\n",
       "      <td>5748</td>\n",
       "      <td>75.878553</td>\n",
       "      <td>2812.668562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_follower_count  A_following_count  A_listed_count  \\\n",
       "0               614689                400            5729   \n",
       "1               739581              10723            1279   \n",
       "2                 3638               3341              85   \n",
       "3                  613               1259              31   \n",
       "4              1352348                331           15647   \n",
       "...                ...                ...             ...   \n",
       "5947            614689                400            5729   \n",
       "5948              3764                703             222   \n",
       "5949           1611042                936           10346   \n",
       "5950            631958                674            7522   \n",
       "5951           2307845                329           12580   \n",
       "\n",
       "      A_mentions_received  A_retweets_received  A_mentions_sent  \\\n",
       "0              199.618296            67.812469         9.366192   \n",
       "1              102.026750            96.771319         1.537322   \n",
       "2                2.793577             1.402703         2.594089   \n",
       "3                1.326041             0.356943         6.249678   \n",
       "4            19129.848662         14552.733991         2.065418   \n",
       "...                   ...                  ...              ...   \n",
       "5947           199.618296            67.812469         9.366192   \n",
       "5948             5.270621             1.601159         2.338333   \n",
       "5949           388.093282            65.719046         2.086961   \n",
       "5950           614.968745           329.330091         4.052279   \n",
       "5951           530.084862           189.947739         4.827720   \n",
       "\n",
       "      A_retweets_sent    A_posts  A_network_feature_1  A_network_feature_2  \\\n",
       "0            0.359534   4.094488                  669            39.193741   \n",
       "1            1.054358   3.467754                  432            11.191686   \n",
       "2            0.598150   3.802143                   11             9.416667   \n",
       "3            2.323064   7.488116                    4             5.000000   \n",
       "4            0.580955  16.281502                52580             3.092448   \n",
       "...               ...        ...                  ...                  ...   \n",
       "5947         0.359534   4.094488                  669            39.193741   \n",
       "5948         0.100503   1.596539                   18           139.444444   \n",
       "5949         0.349327   1.096322                 1637            35.500603   \n",
       "5950         1.340566  12.305035                 2536            35.838659   \n",
       "5951         0.100503   3.130447                 2164            80.914768   \n",
       "\n",
       "      ...  B_following_count  B_listed_count  B_mentions_received  \\\n",
       "0     ...                563           20057           967.720642   \n",
       "1     ...              12949            1311            38.260522   \n",
       "2     ...                320            3673          1207.190077   \n",
       "3     ...               3599            1072            10.300222   \n",
       "4     ...             147521           15043          9902.070379   \n",
       "...   ...                ...             ...                  ...   \n",
       "5947  ...             550744           20006           936.636126   \n",
       "5948  ...               3557               9             0.751434   \n",
       "5949  ...                140           13838           133.213345   \n",
       "5950  ...               2799            7371           296.978205   \n",
       "5951  ...                240           39725          1404.436304   \n",
       "\n",
       "      B_retweets_received  B_mentions_sent  B_retweets_sent     B_posts  \\\n",
       "0              579.431128         4.473798         0.805680    6.241806   \n",
       "1               10.697567        12.845793         1.584284   12.106662   \n",
       "2              599.721600         0.842022         0.593199    7.044735   \n",
       "3                3.828561         1.624092         0.100503    1.614287   \n",
       "4             5012.055876        10.438460         0.100503  193.072418   \n",
       "...                   ...              ...              ...         ...   \n",
       "5947           206.101772        41.317189         0.595962   42.813704   \n",
       "5948             0.295998         0.100503         0.100503    0.100503   \n",
       "5949            56.027747         2.622550         1.121160    2.622550   \n",
       "5950           135.831429        15.033026         4.807180    8.262063   \n",
       "5951           431.103945         2.596749         0.100503    5.559490   \n",
       "\n",
       "      B_network_feature_1  B_network_feature_2  B_network_feature_3  \n",
       "0                    4027            57.643839          3201.293706  \n",
       "1                     144           209.717241         21496.565517  \n",
       "2                    3918             7.859818           637.983300  \n",
       "3                      43           113.840909          2537.772727  \n",
       "4                   28564            10.964144          1035.955493  \n",
       "...                   ...                  ...                  ...  \n",
       "5947                 3691            69.150872          3456.096107  \n",
       "5948                    3             2.666667           218.333333  \n",
       "5949                  562           135.158451          5187.500000  \n",
       "5950                 1201            87.183775          3547.782285  \n",
       "5951                 5748            75.878553          2812.668562  \n",
       "\n",
       "[5952 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "train\n",
    "\n",
    "test = pd.read_csv('test.csv')\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "641ef32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice                 0\n",
       "A_follower_count       0\n",
       "A_following_count      0\n",
       "A_listed_count         0\n",
       "A_mentions_received    0\n",
       "A_retweets_received    0\n",
       "A_mentions_sent        0\n",
       "A_retweets_sent        0\n",
       "A_posts                0\n",
       "A_network_feature_1    0\n",
       "A_network_feature_2    0\n",
       "A_network_feature_3    0\n",
       "B_follower_count       0\n",
       "B_following_count      0\n",
       "B_listed_count         0\n",
       "B_mentions_received    0\n",
       "B_retweets_received    0\n",
       "B_mentions_sent        0\n",
       "B_retweets_sent        0\n",
       "B_posts                0\n",
       "B_network_feature_1    0\n",
       "B_network_feature_2    0\n",
       "B_network_feature_3    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning the data\n",
    "#Identifying presence of NAs\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f1948d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>A_network_feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>following_diffrat</th>\n",
       "      <th>listed_diffrat</th>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <th>posts_diffrat</th>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <th>nf3_diffrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>614689</td>\n",
       "      <td>400</td>\n",
       "      <td>5729</td>\n",
       "      <td>199.618296</td>\n",
       "      <td>67.812469</td>\n",
       "      <td>9.366192</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>4.094488</td>\n",
       "      <td>669</td>\n",
       "      <td>39.193741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169263</td>\n",
       "      <td>-0.555650</td>\n",
       "      <td>-0.657994</td>\n",
       "      <td>-0.790458</td>\n",
       "      <td>0.353497</td>\n",
       "      <td>-0.382888</td>\n",
       "      <td>-0.207745</td>\n",
       "      <td>-0.715077</td>\n",
       "      <td>-0.190526</td>\n",
       "      <td>-0.110229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>739581</td>\n",
       "      <td>10723</td>\n",
       "      <td>1279</td>\n",
       "      <td>102.026750</td>\n",
       "      <td>96.771319</td>\n",
       "      <td>1.537322</td>\n",
       "      <td>1.054358</td>\n",
       "      <td>3.467754</td>\n",
       "      <td>432</td>\n",
       "      <td>11.191686</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094035</td>\n",
       "      <td>-0.012355</td>\n",
       "      <td>0.454540</td>\n",
       "      <td>0.800918</td>\n",
       "      <td>-0.786232</td>\n",
       "      <td>-0.200833</td>\n",
       "      <td>-0.554686</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.898676</td>\n",
       "      <td>-0.913974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3638</td>\n",
       "      <td>3341</td>\n",
       "      <td>85</td>\n",
       "      <td>2.793577</td>\n",
       "      <td>1.402703</td>\n",
       "      <td>2.594089</td>\n",
       "      <td>0.598150</td>\n",
       "      <td>3.802143</td>\n",
       "      <td>11</td>\n",
       "      <td>9.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825184</td>\n",
       "      <td>-0.954763</td>\n",
       "      <td>-0.995382</td>\n",
       "      <td>-0.995333</td>\n",
       "      <td>0.509898</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>-0.298942</td>\n",
       "      <td>-0.994401</td>\n",
       "      <td>0.090114</td>\n",
       "      <td>-0.132113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>613</td>\n",
       "      <td>1259</td>\n",
       "      <td>31</td>\n",
       "      <td>1.326041</td>\n",
       "      <td>0.356943</td>\n",
       "      <td>6.249678</td>\n",
       "      <td>2.323064</td>\n",
       "      <td>7.488116</td>\n",
       "      <td>4</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.481680</td>\n",
       "      <td>-0.943790</td>\n",
       "      <td>-0.771889</td>\n",
       "      <td>-0.829438</td>\n",
       "      <td>0.587468</td>\n",
       "      <td>0.917062</td>\n",
       "      <td>0.645305</td>\n",
       "      <td>-0.829787</td>\n",
       "      <td>-0.915854</td>\n",
       "      <td>-0.804463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1352348</td>\n",
       "      <td>331</td>\n",
       "      <td>15647</td>\n",
       "      <td>19129.848662</td>\n",
       "      <td>14552.733991</td>\n",
       "      <td>2.065418</td>\n",
       "      <td>0.580955</td>\n",
       "      <td>16.281502</td>\n",
       "      <td>52580</td>\n",
       "      <td>3.092448</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.995523</td>\n",
       "      <td>0.019681</td>\n",
       "      <td>0.317849</td>\n",
       "      <td>0.487645</td>\n",
       "      <td>-0.669636</td>\n",
       "      <td>0.705035</td>\n",
       "      <td>-0.844460</td>\n",
       "      <td>0.295968</td>\n",
       "      <td>-0.560000</td>\n",
       "      <td>-0.268373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>614689</td>\n",
       "      <td>400</td>\n",
       "      <td>5729</td>\n",
       "      <td>199.618296</td>\n",
       "      <td>67.812469</td>\n",
       "      <td>9.366192</td>\n",
       "      <td>0.359534</td>\n",
       "      <td>4.094488</td>\n",
       "      <td>669</td>\n",
       "      <td>39.193741</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998548</td>\n",
       "      <td>-0.554770</td>\n",
       "      <td>-0.648638</td>\n",
       "      <td>-0.504864</td>\n",
       "      <td>-0.630404</td>\n",
       "      <td>-0.247441</td>\n",
       "      <td>-0.825425</td>\n",
       "      <td>-0.693119</td>\n",
       "      <td>-0.276499</td>\n",
       "      <td>-0.147879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>3764</td>\n",
       "      <td>703</td>\n",
       "      <td>222</td>\n",
       "      <td>5.270621</td>\n",
       "      <td>1.601159</td>\n",
       "      <td>2.338333</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>1.596539</td>\n",
       "      <td>18</td>\n",
       "      <td>139.444444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.669953</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.750439</td>\n",
       "      <td>0.687956</td>\n",
       "      <td>0.917581</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.881555</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.962471</td>\n",
       "      <td>0.908880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>1611042</td>\n",
       "      <td>936</td>\n",
       "      <td>10346</td>\n",
       "      <td>388.093282</td>\n",
       "      <td>65.719046</td>\n",
       "      <td>2.086961</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>1.096322</td>\n",
       "      <td>1637</td>\n",
       "      <td>35.500603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739777</td>\n",
       "      <td>-0.144393</td>\n",
       "      <td>0.488925</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>-0.113725</td>\n",
       "      <td>-0.524883</td>\n",
       "      <td>-0.410401</td>\n",
       "      <td>0.488859</td>\n",
       "      <td>-0.583959</td>\n",
       "      <td>-0.189031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>631958</td>\n",
       "      <td>674</td>\n",
       "      <td>7522</td>\n",
       "      <td>614.968745</td>\n",
       "      <td>329.330091</td>\n",
       "      <td>4.052279</td>\n",
       "      <td>1.340566</td>\n",
       "      <td>12.305035</td>\n",
       "      <td>2536</td>\n",
       "      <td>35.838659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611863</td>\n",
       "      <td>0.010139</td>\n",
       "      <td>0.348694</td>\n",
       "      <td>0.415982</td>\n",
       "      <td>-0.575351</td>\n",
       "      <td>-0.563884</td>\n",
       "      <td>0.196575</td>\n",
       "      <td>0.357238</td>\n",
       "      <td>-0.417364</td>\n",
       "      <td>-0.227744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>2307845</td>\n",
       "      <td>329</td>\n",
       "      <td>12580</td>\n",
       "      <td>530.084862</td>\n",
       "      <td>189.947739</td>\n",
       "      <td>4.827720</td>\n",
       "      <td>0.100503</td>\n",
       "      <td>3.130447</td>\n",
       "      <td>2164</td>\n",
       "      <td>80.914768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156415</td>\n",
       "      <td>-0.518975</td>\n",
       "      <td>-0.451973</td>\n",
       "      <td>-0.388303</td>\n",
       "      <td>0.300489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.279524</td>\n",
       "      <td>-0.452983</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.534757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_follower_count  A_following_count  A_listed_count  \\\n",
       "0               614689                400            5729   \n",
       "1               739581              10723            1279   \n",
       "2                 3638               3341              85   \n",
       "3                  613               1259              31   \n",
       "4              1352348                331           15647   \n",
       "...                ...                ...             ...   \n",
       "5947            614689                400            5729   \n",
       "5948              3764                703             222   \n",
       "5949           1611042                936           10346   \n",
       "5950            631958                674            7522   \n",
       "5951           2307845                329           12580   \n",
       "\n",
       "      A_mentions_received  A_retweets_received  A_mentions_sent  \\\n",
       "0              199.618296            67.812469         9.366192   \n",
       "1              102.026750            96.771319         1.537322   \n",
       "2                2.793577             1.402703         2.594089   \n",
       "3                1.326041             0.356943         6.249678   \n",
       "4            19129.848662         14552.733991         2.065418   \n",
       "...                   ...                  ...              ...   \n",
       "5947           199.618296            67.812469         9.366192   \n",
       "5948             5.270621             1.601159         2.338333   \n",
       "5949           388.093282            65.719046         2.086961   \n",
       "5950           614.968745           329.330091         4.052279   \n",
       "5951           530.084862           189.947739         4.827720   \n",
       "\n",
       "      A_retweets_sent    A_posts  A_network_feature_1  A_network_feature_2  \\\n",
       "0            0.359534   4.094488                  669            39.193741   \n",
       "1            1.054358   3.467754                  432            11.191686   \n",
       "2            0.598150   3.802143                   11             9.416667   \n",
       "3            2.323064   7.488116                    4             5.000000   \n",
       "4            0.580955  16.281502                52580             3.092448   \n",
       "...               ...        ...                  ...                  ...   \n",
       "5947         0.359534   4.094488                  669            39.193741   \n",
       "5948         0.100503   1.596539                   18           139.444444   \n",
       "5949         0.349327   1.096322                 1637            35.500603   \n",
       "5950         1.340566  12.305035                 2536            35.838659   \n",
       "5951         0.100503   3.130447                 2164            80.914768   \n",
       "\n",
       "      ...  following_diffrat  listed_diffrat  ment_rec_diffrat  \\\n",
       "0     ...          -0.169263       -0.555650         -0.657994   \n",
       "1     ...          -0.094035       -0.012355          0.454540   \n",
       "2     ...           0.825184       -0.954763         -0.995382   \n",
       "3     ...          -0.481680       -0.943790         -0.771889   \n",
       "4     ...          -0.995523        0.019681          0.317849   \n",
       "...   ...                ...             ...               ...   \n",
       "5947  ...          -0.998548       -0.554770         -0.648638   \n",
       "5948  ...          -0.669953        0.922078          0.750439   \n",
       "5949  ...           0.739777       -0.144393          0.488925   \n",
       "5950  ...          -0.611863        0.010139          0.348694   \n",
       "5951  ...           0.156415       -0.518975         -0.451973   \n",
       "\n",
       "      rt_rec_diffrat  ment_sent_diffrat  rt_sent_diffrat  posts_diffrat  \\\n",
       "0          -0.790458           0.353497        -0.382888      -0.207745   \n",
       "1           0.800918          -0.786232        -0.200833      -0.554686   \n",
       "2          -0.995333           0.509898         0.004156      -0.298942   \n",
       "3          -0.829438           0.587468         0.917062       0.645305   \n",
       "4           0.487645          -0.669636         0.705035      -0.844460   \n",
       "...              ...                ...              ...            ...   \n",
       "5947       -0.504864          -0.630404        -0.247441      -0.825425   \n",
       "5948        0.687956           0.917581         0.000000       0.881555   \n",
       "5949        0.079602          -0.113725        -0.524883      -0.410401   \n",
       "5950        0.415982          -0.575351        -0.563884       0.196575   \n",
       "5951       -0.388303           0.300489         0.000000      -0.279524   \n",
       "\n",
       "      nf1_diffrat  nf2_diffrat  nf3_diffrat  \n",
       "0       -0.715077    -0.190526    -0.110229  \n",
       "1        0.500000    -0.898676    -0.913974  \n",
       "2       -0.994401     0.090114    -0.132113  \n",
       "3       -0.829787    -0.915854    -0.804463  \n",
       "4        0.295968    -0.560000    -0.268373  \n",
       "...           ...          ...          ...  \n",
       "5947    -0.693119    -0.276499    -0.147879  \n",
       "5948     0.714286     0.962471     0.908880  \n",
       "5949     0.488859    -0.583959    -0.189031  \n",
       "5950     0.357238    -0.417364    -0.227744  \n",
       "5951    -0.452983     0.032120     0.534757  \n",
       "\n",
       "[5952 rows x 66 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the required columns\n",
    "def feat_eng(df):\n",
    "    df.replace(0, 0.001)\n",
    "    \n",
    "    df['follower_diff'] = (df['A_follower_count'] - df['B_follower_count'])\n",
    "    df['following_diff'] = (df['A_following_count'] - df['B_following_count'])\n",
    "    df['listed_diff'] = (df['A_listed_count'] - df['B_listed_count'])\n",
    "    df['ment_rec_diff'] = (df['A_mentions_received'] - df['B_mentions_received'])\n",
    "    df['rt_rec_diff'] = (df['A_retweets_received'] - df['B_retweets_received'])\n",
    "    df['ment_sent_diff'] = (df['A_mentions_sent'] - df['B_mentions_sent'])\n",
    "    df['rt_sent_diff'] = (df['A_retweets_sent'] - df['B_retweets_sent'])\n",
    "    df['posts_diff'] = (df['A_posts'] - df['B_posts'])\n",
    "    \n",
    "    df['follower_ratio'] = (df['A_follower_count'] / df['B_follower_count'])\n",
    "    df['following_ratio'] = (df['A_following_count'] / df['B_following_count'])\n",
    "    df['listed_ratio'] = (df['A_listed_count'] / df['B_listed_count'])\n",
    "    df['ment_rec_ratio'] = (df['A_mentions_received'] / df['B_mentions_received'])\n",
    "    df['rt_rec_ratio'] = (df['A_retweets_received'] / df['B_retweets_received'])\n",
    "    df['ment_sent_ratio'] = (df['A_mentions_sent'] / df['B_mentions_sent'])\n",
    "    df['rt_sent_ratio'] = (df['A_retweets_sent'] / df['B_retweets_sent'])\n",
    "    df['posts_ratio'] = (df['A_posts'] - df['B_posts'])\n",
    "\n",
    "    df['A_pop_ratio'] = df['A_mentions_sent'] / df['A_listed_count']\n",
    "    df['A_foll_ratio'] = df['A_follower_count'] / df['A_following_count']\n",
    "    df['A_ment_ratio'] = df['A_mentions_sent'] / df['A_mentions_received']\n",
    "    df['A_rt_ratio'] = df['A_retweets_sent'] / df['A_retweets_received']\n",
    "    \n",
    "    df['B_pop_ratio'] = df['B_mentions_sent'] / df['B_listed_count']\n",
    "    df['B_foll_ratio'] = df['B_follower_count'] / df['B_following_count']\n",
    "    df['B_ment_ratio'] = df['B_mentions_sent'] / df['B_mentions_received']\n",
    "    df['B_rt_ratio'] = df['B_retweets_sent'] / df['B_retweets_received']\n",
    "    \n",
    "    df['AB_foll_ratio'] = (df['A_foll_ratio'] - df['B_foll_ratio'])\n",
    "    df['AB_ment_ratio'] = (df['A_ment_ratio'] - df['B_ment_ratio'])\n",
    "    df['AB_rt_ratio'] = (df['A_rt_ratio'] - df['B_rt_ratio'])\n",
    "\n",
    "    df['nf1_diff'] = (df['A_network_feature_1'] - df['B_network_feature_1'])\n",
    "    df['nf2_diff'] = (df['A_network_feature_2'] - df['B_network_feature_2'])\n",
    "    df['nf3_diff'] = (df['A_network_feature_3'] - df['B_network_feature_3'])\n",
    "    \n",
    "    df['nf3_ratio'] = df['A_network_feature_3'] / df['B_network_feature_3']\n",
    "    df['nf2_ratio'] = df['A_network_feature_2'] / df['B_network_feature_2']\n",
    "    df['nf1_ratio'] = df['A_network_feature_1'] / df['B_network_feature_1']\n",
    "    \n",
    "    df['follower_diffrat'] = ((df['A_follower_count'] - df['B_follower_count']) / (df['A_follower_count'] + df['B_follower_count']))\n",
    "    df['following_diffrat'] = ((df['A_following_count'] - df['B_following_count']) / (df['A_following_count'] + df['B_following_count']))\n",
    "    df['listed_diffrat'] = ((df['A_listed_count'] - df['B_listed_count']) / (df['A_listed_count'] + df['B_listed_count']))\n",
    "    df['ment_rec_diffrat'] = ((df['A_mentions_received'] - df['B_mentions_received']) / (df['A_mentions_received'] + df['B_mentions_received']))\n",
    "    df['rt_rec_diffrat'] = ((df['A_retweets_received'] - df['B_retweets_received']) / (df['A_retweets_received'] + df['B_retweets_received']))\n",
    "    df['ment_sent_diffrat'] = ((df['A_mentions_sent'] - df['B_mentions_sent']) / (df['A_mentions_sent'] + df['B_mentions_sent']))\n",
    "    df['rt_sent_diffrat'] = ((df['A_retweets_sent'] - df['B_retweets_sent']) / (df['A_retweets_sent'] + df['B_retweets_sent']))\n",
    "    df['posts_diffrat'] = ((df['A_posts'] - df['B_posts']) / (df['A_posts'] + df['B_posts']))\n",
    "    \n",
    "    df['nf1_diffrat'] = ((df['A_network_feature_1'] - df['B_network_feature_1']) / (df['A_network_feature_1'] + df['B_network_feature_1']))\n",
    "    df['nf2_diffrat'] = ((df['A_network_feature_2'] - df['B_network_feature_2']) / (df['A_network_feature_2'] + df['B_network_feature_2']))\n",
    "    df['nf3_diffrat'] = ((df['A_network_feature_3'] - df['B_network_feature_3']) / (df['A_network_feature_3'] + df['B_network_feature_3']))\n",
    "    \n",
    "    df = df.replace([np.inf, -np.inf], 1)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "train = feat_eng(train)\n",
    "train\n",
    "\n",
    "test = feat_eng(test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1d4f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>A_network_feature_2</th>\n",
       "      <th>...</th>\n",
       "      <th>following_diffrat</th>\n",
       "      <th>listed_diffrat</th>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <th>posts_diffrat</th>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <th>nf3_diffrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.553648e-04</td>\n",
       "      <td>0.095940</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.033461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.415369</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>0.171003</td>\n",
       "      <td>0.104770</td>\n",
       "      <td>0.677212</td>\n",
       "      <td>0.308196</td>\n",
       "      <td>0.396019</td>\n",
       "      <td>0.142462</td>\n",
       "      <td>0.404737</td>\n",
       "      <td>0.444885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020238</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>2.218107e-04</td>\n",
       "      <td>0.014877</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.017449</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.452982</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.727272</td>\n",
       "      <td>0.900462</td>\n",
       "      <td>0.105854</td>\n",
       "      <td>0.400229</td>\n",
       "      <td>0.222368</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.050662</td>\n",
       "      <td>0.043013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.987890e-06</td>\n",
       "      <td>0.025819</td>\n",
       "      <td>0.018588</td>\n",
       "      <td>0.019182</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.008039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.912592</td>\n",
       "      <td>0.022618</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.755617</td>\n",
       "      <td>0.503855</td>\n",
       "      <td>0.350373</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.545057</td>\n",
       "      <td>0.433944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>5.884001e-07</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.083016</td>\n",
       "      <td>0.038283</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259160</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.114055</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.965348</td>\n",
       "      <td>0.822989</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.097768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037006</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.028493</td>\n",
       "      <td>0.016704</td>\n",
       "      <td>3.339094e-02</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>0.083852</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.002640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.509840</td>\n",
       "      <td>0.658927</td>\n",
       "      <td>0.743824</td>\n",
       "      <td>0.164305</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.647984</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.365814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.010433</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.553648e-04</td>\n",
       "      <td>0.095940</td>\n",
       "      <td>0.009675</td>\n",
       "      <td>0.020697</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.033461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.222615</td>\n",
       "      <td>0.175681</td>\n",
       "      <td>0.247568</td>\n",
       "      <td>0.183972</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.086857</td>\n",
       "      <td>0.153440</td>\n",
       "      <td>0.361751</td>\n",
       "      <td>0.426061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.443246e-06</td>\n",
       "      <td>0.023171</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>0.959993</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>0.941236</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.981235</td>\n",
       "      <td>0.954440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>0.044085</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>1.505614e-04</td>\n",
       "      <td>0.020568</td>\n",
       "      <td>0.009294</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.001778</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.427804</td>\n",
       "      <td>0.744465</td>\n",
       "      <td>0.539802</td>\n",
       "      <td>0.442989</td>\n",
       "      <td>0.236415</td>\n",
       "      <td>0.294586</td>\n",
       "      <td>0.744429</td>\n",
       "      <td>0.208021</td>\n",
       "      <td>0.405484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.013698</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>7.554156e-04</td>\n",
       "      <td>0.040918</td>\n",
       "      <td>0.046318</td>\n",
       "      <td>0.063245</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.030596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194069</td>\n",
       "      <td>0.505069</td>\n",
       "      <td>0.674349</td>\n",
       "      <td>0.707992</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.216699</td>\n",
       "      <td>0.598390</td>\n",
       "      <td>0.678619</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.386128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>0.063153</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.022908</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>4.356035e-04</td>\n",
       "      <td>0.048947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015701</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.069079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578207</td>\n",
       "      <td>0.240512</td>\n",
       "      <td>0.274014</td>\n",
       "      <td>0.305848</td>\n",
       "      <td>0.650638</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>0.360093</td>\n",
       "      <td>0.273509</td>\n",
       "      <td>0.516060</td>\n",
       "      <td>0.767379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_follower_count  A_following_count  A_listed_count  \\\n",
       "0             0.016820           0.000726        0.010433   \n",
       "1             0.020238           0.019470        0.002329   \n",
       "2             0.000099           0.006066        0.000155   \n",
       "3             0.000016           0.002286        0.000056   \n",
       "4             0.037006           0.000601        0.028493   \n",
       "...                ...                ...             ...   \n",
       "5947          0.016820           0.000726        0.010433   \n",
       "5948          0.000102           0.001276        0.000404   \n",
       "5949          0.044085           0.001700        0.018840   \n",
       "5950          0.017293           0.001224        0.013698   \n",
       "5951          0.063153           0.000597        0.022908   \n",
       "\n",
       "      A_mentions_received  A_retweets_received  A_mentions_sent  \\\n",
       "0                0.000174         1.553648e-04         0.095940   \n",
       "1                0.000089         2.218107e-04         0.014877   \n",
       "2                0.000002         2.987890e-06         0.025819   \n",
       "3                0.000001         5.884001e-07         0.063670   \n",
       "4                0.016704         3.339094e-02         0.020345   \n",
       "...                   ...                  ...              ...   \n",
       "5947             0.000174         1.553648e-04         0.095940   \n",
       "5948             0.000005         3.443246e-06         0.023171   \n",
       "5949             0.000339         1.505614e-04         0.020568   \n",
       "5950             0.000537         7.554156e-04         0.040918   \n",
       "5951             0.000463         4.356035e-04         0.048947   \n",
       "\n",
       "      A_retweets_sent   A_posts  A_network_feature_1  A_network_feature_2  \\\n",
       "0            0.009675  0.020697             0.000727             0.033461   \n",
       "1            0.035628  0.017449             0.000469             0.009555   \n",
       "2            0.018588  0.019182             0.000012             0.008039   \n",
       "3            0.083016  0.038283             0.000004             0.004269   \n",
       "4            0.017946  0.083852             0.057100             0.002640   \n",
       "...               ...       ...                  ...                  ...   \n",
       "5947         0.009675  0.020697             0.000727             0.033461   \n",
       "5948         0.000000  0.007753             0.000020             0.119048   \n",
       "5949         0.009294  0.005160             0.001778             0.030308   \n",
       "5950         0.046318  0.063245             0.002754             0.030596   \n",
       "5951         0.000000  0.015701             0.002350             0.069079   \n",
       "\n",
       "      ...  following_diffrat  listed_diffrat  ment_rec_diffrat  \\\n",
       "0     ...           0.415369        0.222175          0.171003   \n",
       "1     ...           0.452982        0.493822          0.727272   \n",
       "2     ...           0.912592        0.022618          0.002308   \n",
       "3     ...           0.259160        0.028105          0.114055   \n",
       "4     ...           0.002239        0.509840          0.658927   \n",
       "...   ...                ...             ...               ...   \n",
       "5947  ...           0.000726        0.222615          0.175681   \n",
       "5948  ...           0.165023        0.961039          0.875222   \n",
       "5949  ...           0.869888        0.427804          0.744465   \n",
       "5950  ...           0.194069        0.505069          0.674349   \n",
       "5951  ...           0.578207        0.240512          0.274014   \n",
       "\n",
       "      rt_rec_diffrat  ment_sent_diffrat  rt_sent_diffrat  posts_diffrat  \\\n",
       "0           0.104770           0.677212         0.308196       0.396019   \n",
       "1           0.900462           0.105854         0.400229       0.222368   \n",
       "2           0.002332           0.755617         0.503855       0.350373   \n",
       "3           0.085279           0.794504         0.965348       0.822989   \n",
       "4           0.743824           0.164305         0.858164       0.077330   \n",
       "...              ...                ...              ...            ...   \n",
       "5947        0.247568           0.183972         0.376667       0.086857   \n",
       "5948        0.843980           0.959993         0.501754       0.941236   \n",
       "5949        0.539802           0.442989         0.236415       0.294586   \n",
       "5950        0.707992           0.211571         0.216699       0.598390   \n",
       "5951        0.305848           0.650638         0.501754       0.360093   \n",
       "\n",
       "      nf1_diffrat  nf2_diffrat  nf3_diffrat  \n",
       "0        0.142462     0.404737     0.444885  \n",
       "1        0.750000     0.050662     0.043013  \n",
       "2        0.002800     0.545057     0.433944  \n",
       "3        0.085106     0.042073     0.097768  \n",
       "4        0.647984     0.220000     0.365814  \n",
       "...           ...          ...          ...  \n",
       "5947     0.153440     0.361751     0.426061  \n",
       "5948     0.857143     0.981235     0.954440  \n",
       "5949     0.744429     0.208021     0.405484  \n",
       "5950     0.678619     0.291318     0.386128  \n",
       "5951     0.273509     0.516060     0.767379  \n",
       "\n",
       "[5952 rows x 66 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalize and center the variables\n",
    "def normalize(df):\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        max_value = df[feature_name].max()\n",
    "        min_value = df[feature_name].min()\n",
    "        result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result\n",
    "\n",
    "train = normalize(train)\n",
    "test = normalize(test)\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beb9dec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Choice</th>\n",
       "      <th>A_follower_count</th>\n",
       "      <th>A_following_count</th>\n",
       "      <th>A_listed_count</th>\n",
       "      <th>A_mentions_received</th>\n",
       "      <th>A_retweets_received</th>\n",
       "      <th>A_mentions_sent</th>\n",
       "      <th>A_retweets_sent</th>\n",
       "      <th>A_posts</th>\n",
       "      <th>A_network_feature_1</th>\n",
       "      <th>...</th>\n",
       "      <th>following_diffrat</th>\n",
       "      <th>listed_diffrat</th>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <th>posts_diffrat</th>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <th>nf3_diffrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Choice</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134133</td>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.135078</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.024139</td>\n",
       "      <td>0.123868</td>\n",
       "      <td>0.137833</td>\n",
       "      <td>0.107648</td>\n",
       "      <td>0.065543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168821</td>\n",
       "      <td>0.594599</td>\n",
       "      <td>0.558203</td>\n",
       "      <td>0.545148</td>\n",
       "      <td>0.334841</td>\n",
       "      <td>0.287329</td>\n",
       "      <td>0.334249</td>\n",
       "      <td>0.566896</td>\n",
       "      <td>0.190618</td>\n",
       "      <td>0.275049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_follower_count</th>\n",
       "      <td>0.134133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.115834</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.511609</td>\n",
       "      <td>0.521888</td>\n",
       "      <td>0.018456</td>\n",
       "      <td>0.094799</td>\n",
       "      <td>0.042993</td>\n",
       "      <td>0.622146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017440</td>\n",
       "      <td>0.241977</td>\n",
       "      <td>0.244728</td>\n",
       "      <td>0.235023</td>\n",
       "      <td>0.038255</td>\n",
       "      <td>0.057404</td>\n",
       "      <td>0.052929</td>\n",
       "      <td>0.244192</td>\n",
       "      <td>-0.108401</td>\n",
       "      <td>-0.016422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_following_count</th>\n",
       "      <td>0.063678</td>\n",
       "      <td>0.115834</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.051819</td>\n",
       "      <td>0.111342</td>\n",
       "      <td>-0.083883</td>\n",
       "      <td>0.138373</td>\n",
       "      <td>0.047236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298154</td>\n",
       "      <td>0.124169</td>\n",
       "      <td>0.101086</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.001627</td>\n",
       "      <td>-0.083092</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>0.063669</td>\n",
       "      <td>0.108214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_listed_count</th>\n",
       "      <td>0.135078</td>\n",
       "      <td>0.815952</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734589</td>\n",
       "      <td>0.747752</td>\n",
       "      <td>0.061729</td>\n",
       "      <td>0.155630</td>\n",
       "      <td>0.053975</td>\n",
       "      <td>0.705268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041950</td>\n",
       "      <td>0.258081</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.216469</td>\n",
       "      <td>0.078915</td>\n",
       "      <td>0.095988</td>\n",
       "      <td>0.092879</td>\n",
       "      <td>0.224286</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>0.013682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A_mentions_received</th>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.511609</td>\n",
       "      <td>0.058140</td>\n",
       "      <td>0.734589</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990021</td>\n",
       "      <td>0.023336</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>0.026512</td>\n",
       "      <td>0.922340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037779</td>\n",
       "      <td>0.073286</td>\n",
       "      <td>0.100632</td>\n",
       "      <td>0.096361</td>\n",
       "      <td>0.048691</td>\n",
       "      <td>0.057358</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>0.097461</td>\n",
       "      <td>-0.057826</td>\n",
       "      <td>-0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <td>0.287329</td>\n",
       "      <td>0.057404</td>\n",
       "      <td>-0.083092</td>\n",
       "      <td>0.095988</td>\n",
       "      <td>0.057358</td>\n",
       "      <td>0.050842</td>\n",
       "      <td>0.341415</td>\n",
       "      <td>0.501889</td>\n",
       "      <td>0.192968</td>\n",
       "      <td>0.060913</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053254</td>\n",
       "      <td>0.320650</td>\n",
       "      <td>0.428336</td>\n",
       "      <td>0.418339</td>\n",
       "      <td>0.710424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.593429</td>\n",
       "      <td>0.425843</td>\n",
       "      <td>0.150617</td>\n",
       "      <td>0.180210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts_diffrat</th>\n",
       "      <td>0.334249</td>\n",
       "      <td>0.052929</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>0.092879</td>\n",
       "      <td>0.059031</td>\n",
       "      <td>0.061177</td>\n",
       "      <td>0.420646</td>\n",
       "      <td>0.317529</td>\n",
       "      <td>0.396531</td>\n",
       "      <td>0.096697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156300</td>\n",
       "      <td>0.417238</td>\n",
       "      <td>0.593168</td>\n",
       "      <td>0.587911</td>\n",
       "      <td>0.829699</td>\n",
       "      <td>0.593429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.582588</td>\n",
       "      <td>0.178337</td>\n",
       "      <td>0.254230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <td>0.566896</td>\n",
       "      <td>0.244192</td>\n",
       "      <td>0.096725</td>\n",
       "      <td>0.224286</td>\n",
       "      <td>0.097461</td>\n",
       "      <td>0.100856</td>\n",
       "      <td>0.266221</td>\n",
       "      <td>0.241636</td>\n",
       "      <td>0.257410</td>\n",
       "      <td>0.185101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176965</td>\n",
       "      <td>0.817114</td>\n",
       "      <td>0.995094</td>\n",
       "      <td>0.948084</td>\n",
       "      <td>0.522756</td>\n",
       "      <td>0.425843</td>\n",
       "      <td>0.582588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.133620</td>\n",
       "      <td>0.300443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <td>0.190618</td>\n",
       "      <td>-0.108401</td>\n",
       "      <td>0.063669</td>\n",
       "      <td>-0.026145</td>\n",
       "      <td>-0.057826</td>\n",
       "      <td>-0.062477</td>\n",
       "      <td>0.088493</td>\n",
       "      <td>0.018811</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>-0.111880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292267</td>\n",
       "      <td>0.230534</td>\n",
       "      <td>0.122619</td>\n",
       "      <td>0.073974</td>\n",
       "      <td>0.288726</td>\n",
       "      <td>0.150617</td>\n",
       "      <td>0.178337</td>\n",
       "      <td>0.133620</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf3_diffrat</th>\n",
       "      <td>0.275049</td>\n",
       "      <td>-0.016422</td>\n",
       "      <td>0.108214</td>\n",
       "      <td>0.013682</td>\n",
       "      <td>-0.028169</td>\n",
       "      <td>-0.030683</td>\n",
       "      <td>0.119991</td>\n",
       "      <td>0.044718</td>\n",
       "      <td>0.032610</td>\n",
       "      <td>-0.052979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334739</td>\n",
       "      <td>0.352321</td>\n",
       "      <td>0.292496</td>\n",
       "      <td>0.247177</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>0.180210</td>\n",
       "      <td>0.254230</td>\n",
       "      <td>0.300443</td>\n",
       "      <td>0.860177</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Choice  A_follower_count  A_following_count  \\\n",
       "Choice               1.000000          0.134133           0.063678   \n",
       "A_follower_count     0.134133          1.000000           0.115834   \n",
       "A_following_count    0.063678          0.115834           1.000000   \n",
       "A_listed_count       0.135078          0.815952           0.100696   \n",
       "A_mentions_received  0.020745          0.511609           0.058140   \n",
       "...                       ...               ...                ...   \n",
       "rt_sent_diffrat      0.287329          0.057404          -0.083092   \n",
       "posts_diffrat        0.334249          0.052929           0.003942   \n",
       "nf1_diffrat          0.566896          0.244192           0.096725   \n",
       "nf2_diffrat          0.190618         -0.108401           0.063669   \n",
       "nf3_diffrat          0.275049         -0.016422           0.108214   \n",
       "\n",
       "                     A_listed_count  A_mentions_received  A_retweets_received  \\\n",
       "Choice                     0.135078             0.020745             0.024139   \n",
       "A_follower_count           0.815952             0.511609             0.521888   \n",
       "A_following_count          0.100696             0.058140             0.051819   \n",
       "A_listed_count             1.000000             0.734589             0.747752   \n",
       "A_mentions_received        0.734589             1.000000             0.990021   \n",
       "...                             ...                  ...                  ...   \n",
       "rt_sent_diffrat            0.095988             0.057358             0.050842   \n",
       "posts_diffrat              0.092879             0.059031             0.061177   \n",
       "nf1_diffrat                0.224286             0.097461             0.100856   \n",
       "nf2_diffrat               -0.026145            -0.057826            -0.062477   \n",
       "nf3_diffrat                0.013682            -0.028169            -0.030683   \n",
       "\n",
       "                     A_mentions_sent  A_retweets_sent   A_posts  \\\n",
       "Choice                      0.123868         0.137833  0.107648   \n",
       "A_follower_count            0.018456         0.094799  0.042993   \n",
       "A_following_count           0.111342        -0.083883  0.138373   \n",
       "A_listed_count              0.061729         0.155630  0.053975   \n",
       "A_mentions_received         0.023336         0.050100  0.026512   \n",
       "...                              ...              ...       ...   \n",
       "rt_sent_diffrat             0.341415         0.501889  0.192968   \n",
       "posts_diffrat               0.420646         0.317529  0.396531   \n",
       "nf1_diffrat                 0.266221         0.241636  0.257410   \n",
       "nf2_diffrat                 0.088493         0.018811 -0.038187   \n",
       "nf3_diffrat                 0.119991         0.044718  0.032610   \n",
       "\n",
       "                     A_network_feature_1  ...  following_diffrat  \\\n",
       "Choice                          0.065543  ...           0.168821   \n",
       "A_follower_count                0.622146  ...           0.017440   \n",
       "A_following_count               0.047236  ...           0.298154   \n",
       "A_listed_count                  0.705268  ...           0.041950   \n",
       "A_mentions_received             0.922340  ...           0.037779   \n",
       "...                                  ...  ...                ...   \n",
       "rt_sent_diffrat                 0.060913  ...           0.053254   \n",
       "posts_diffrat                   0.096697  ...           0.156300   \n",
       "nf1_diffrat                     0.185101  ...           0.176965   \n",
       "nf2_diffrat                    -0.111880  ...           0.292267   \n",
       "nf3_diffrat                    -0.052979  ...           0.334739   \n",
       "\n",
       "                     listed_diffrat  ment_rec_diffrat  rt_rec_diffrat  \\\n",
       "Choice                     0.594599          0.558203        0.545148   \n",
       "A_follower_count           0.241977          0.244728        0.235023   \n",
       "A_following_count          0.124169          0.101086        0.096326   \n",
       "A_listed_count             0.258081          0.224222        0.216469   \n",
       "A_mentions_received        0.073286          0.100632        0.096361   \n",
       "...                             ...               ...             ...   \n",
       "rt_sent_diffrat            0.320650          0.428336        0.418339   \n",
       "posts_diffrat              0.417238          0.593168        0.587911   \n",
       "nf1_diffrat                0.817114          0.995094        0.948084   \n",
       "nf2_diffrat                0.230534          0.122619        0.073974   \n",
       "nf3_diffrat                0.352321          0.292496        0.247177   \n",
       "\n",
       "                     ment_sent_diffrat  rt_sent_diffrat  posts_diffrat  \\\n",
       "Choice                        0.334841         0.287329       0.334249   \n",
       "A_follower_count              0.038255         0.057404       0.052929   \n",
       "A_following_count             0.001627        -0.083092       0.003942   \n",
       "A_listed_count                0.078915         0.095988       0.092879   \n",
       "A_mentions_received           0.048691         0.057358       0.059031   \n",
       "...                                ...              ...            ...   \n",
       "rt_sent_diffrat               0.710424         1.000000       0.593429   \n",
       "posts_diffrat                 0.829699         0.593429       1.000000   \n",
       "nf1_diffrat                   0.522756         0.425843       0.582588   \n",
       "nf2_diffrat                   0.288726         0.150617       0.178337   \n",
       "nf3_diffrat                   0.313904         0.180210       0.254230   \n",
       "\n",
       "                     nf1_diffrat  nf2_diffrat  nf3_diffrat  \n",
       "Choice                  0.566896     0.190618     0.275049  \n",
       "A_follower_count        0.244192    -0.108401    -0.016422  \n",
       "A_following_count       0.096725     0.063669     0.108214  \n",
       "A_listed_count          0.224286    -0.026145     0.013682  \n",
       "A_mentions_received     0.097461    -0.057826    -0.028169  \n",
       "...                          ...          ...          ...  \n",
       "rt_sent_diffrat         0.425843     0.150617     0.180210  \n",
       "posts_diffrat           0.582588     0.178337     0.254230  \n",
       "nf1_diffrat             1.000000     0.133620     0.300443  \n",
       "nf2_diffrat             0.133620     1.000000     0.860177  \n",
       "nf3_diffrat             0.300443     0.860177     1.000000  \n",
       "\n",
       "[67 rows x 67 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for correlation\n",
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba6bff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>follower_diffrat</th>\n",
       "      <th>following_diffrat</th>\n",
       "      <th>listed_diffrat</th>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <th>posts_diffrat</th>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <th>nf3_diffrat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304450</td>\n",
       "      <td>0.415369</td>\n",
       "      <td>0.222175</td>\n",
       "      <td>0.171003</td>\n",
       "      <td>0.104770</td>\n",
       "      <td>0.677212</td>\n",
       "      <td>0.308196</td>\n",
       "      <td>0.396019</td>\n",
       "      <td>0.142462</td>\n",
       "      <td>0.404737</td>\n",
       "      <td>0.444885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.494275</td>\n",
       "      <td>0.452982</td>\n",
       "      <td>0.493822</td>\n",
       "      <td>0.727272</td>\n",
       "      <td>0.900462</td>\n",
       "      <td>0.105854</td>\n",
       "      <td>0.400229</td>\n",
       "      <td>0.222368</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.050662</td>\n",
       "      <td>0.043013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007386</td>\n",
       "      <td>0.912592</td>\n",
       "      <td>0.022618</td>\n",
       "      <td>0.002308</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.755617</td>\n",
       "      <td>0.503855</td>\n",
       "      <td>0.350373</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.545057</td>\n",
       "      <td>0.433944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043568</td>\n",
       "      <td>0.259160</td>\n",
       "      <td>0.028105</td>\n",
       "      <td>0.114055</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>0.794504</td>\n",
       "      <td>0.965348</td>\n",
       "      <td>0.822989</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.042073</td>\n",
       "      <td>0.097768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.477234</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.509840</td>\n",
       "      <td>0.658927</td>\n",
       "      <td>0.743824</td>\n",
       "      <td>0.164305</td>\n",
       "      <td>0.858164</td>\n",
       "      <td>0.077330</td>\n",
       "      <td>0.647984</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.365814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5947</th>\n",
       "      <td>0.156920</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.222615</td>\n",
       "      <td>0.175681</td>\n",
       "      <td>0.247568</td>\n",
       "      <td>0.183972</td>\n",
       "      <td>0.376667</td>\n",
       "      <td>0.086857</td>\n",
       "      <td>0.153440</td>\n",
       "      <td>0.361751</td>\n",
       "      <td>0.426061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5948</th>\n",
       "      <td>0.116253</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.875222</td>\n",
       "      <td>0.843980</td>\n",
       "      <td>0.959993</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>0.941236</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.981235</td>\n",
       "      <td>0.954440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5949</th>\n",
       "      <td>0.648911</td>\n",
       "      <td>0.869888</td>\n",
       "      <td>0.427804</td>\n",
       "      <td>0.744465</td>\n",
       "      <td>0.539802</td>\n",
       "      <td>0.442989</td>\n",
       "      <td>0.236415</td>\n",
       "      <td>0.294586</td>\n",
       "      <td>0.744429</td>\n",
       "      <td>0.208021</td>\n",
       "      <td>0.405484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>0.521203</td>\n",
       "      <td>0.194069</td>\n",
       "      <td>0.505069</td>\n",
       "      <td>0.674349</td>\n",
       "      <td>0.707992</td>\n",
       "      <td>0.211571</td>\n",
       "      <td>0.216699</td>\n",
       "      <td>0.598390</td>\n",
       "      <td>0.678619</td>\n",
       "      <td>0.291318</td>\n",
       "      <td>0.386128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5951</th>\n",
       "      <td>0.511047</td>\n",
       "      <td>0.578207</td>\n",
       "      <td>0.240512</td>\n",
       "      <td>0.274014</td>\n",
       "      <td>0.305848</td>\n",
       "      <td>0.650638</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>0.360093</td>\n",
       "      <td>0.273509</td>\n",
       "      <td>0.516060</td>\n",
       "      <td>0.767379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5952 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      follower_diffrat  following_diffrat  listed_diffrat  ment_rec_diffrat  \\\n",
       "0             0.304450           0.415369        0.222175          0.171003   \n",
       "1             0.494275           0.452982        0.493822          0.727272   \n",
       "2             0.007386           0.912592        0.022618          0.002308   \n",
       "3             0.043568           0.259160        0.028105          0.114055   \n",
       "4             0.477234           0.002239        0.509840          0.658927   \n",
       "...                ...                ...             ...               ...   \n",
       "5947          0.156920           0.000726        0.222615          0.175681   \n",
       "5948          0.116253           0.165023        0.961039          0.875222   \n",
       "5949          0.648911           0.869888        0.427804          0.744465   \n",
       "5950          0.521203           0.194069        0.505069          0.674349   \n",
       "5951          0.511047           0.578207        0.240512          0.274014   \n",
       "\n",
       "      rt_rec_diffrat  ment_sent_diffrat  rt_sent_diffrat  posts_diffrat  \\\n",
       "0           0.104770           0.677212         0.308196       0.396019   \n",
       "1           0.900462           0.105854         0.400229       0.222368   \n",
       "2           0.002332           0.755617         0.503855       0.350373   \n",
       "3           0.085279           0.794504         0.965348       0.822989   \n",
       "4           0.743824           0.164305         0.858164       0.077330   \n",
       "...              ...                ...              ...            ...   \n",
       "5947        0.247568           0.183972         0.376667       0.086857   \n",
       "5948        0.843980           0.959993         0.501754       0.941236   \n",
       "5949        0.539802           0.442989         0.236415       0.294586   \n",
       "5950        0.707992           0.211571         0.216699       0.598390   \n",
       "5951        0.305848           0.650638         0.501754       0.360093   \n",
       "\n",
       "      nf1_diffrat  nf2_diffrat  nf3_diffrat  \n",
       "0        0.142462     0.404737     0.444885  \n",
       "1        0.750000     0.050662     0.043013  \n",
       "2        0.002800     0.545057     0.433944  \n",
       "3        0.085106     0.042073     0.097768  \n",
       "4        0.647984     0.220000     0.365814  \n",
       "...           ...          ...          ...  \n",
       "5947     0.153440     0.361751     0.426061  \n",
       "5948     0.857143     0.981235     0.954440  \n",
       "5949     0.744429     0.208021     0.405484  \n",
       "5950     0.678619     0.291318     0.386128  \n",
       "5951     0.273509     0.516060     0.767379  \n",
       "\n",
       "[5952 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Selecting the required variables\n",
    "X = train[['follower_diffrat', 'following_diffrat', 'listed_diffrat', 'ment_rec_diffrat',\n",
    "           'rt_rec_diffrat', 'ment_sent_diffrat', 'rt_sent_diffrat', 'posts_diffrat',\n",
    "           'nf1_diffrat', 'nf2_diffrat', 'nf3_diffrat']]\n",
    "X\n",
    "\n",
    "X_pred = test[['follower_diffrat', 'following_diffrat', 'listed_diffrat', 'ment_rec_diffrat',\n",
    "               'rt_rec_diffrat', 'ment_sent_diffrat', 'rt_sent_diffrat', 'posts_diffrat',\n",
    "               'nf1_diffrat', 'nf2_diffrat', 'nf3_diffrat']]\n",
    "X_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6db610b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       0.0\n",
       "4       1.0\n",
       "       ... \n",
       "5495    0.0\n",
       "5496    1.0\n",
       "5497    0.0\n",
       "5498    0.0\n",
       "5499    0.0\n",
       "Name: Choice, Length: 5500, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning the outcome variable\n",
    "y = train['Choice']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a54f08b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4400, 11)\n",
      "(1100, 11)\n",
      "(4400,)\n",
      "(1100,)\n"
     ]
    }
   ],
   "source": [
    "#Creating training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 147)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982dc7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf761b68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the test data using the model\n",
    "predictions = model.predict(X_test)\n",
    "predictions = [round(num) for num in predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f25fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  0.1272\n",
      "Accuracy:  0.7818\n",
      "R2:  0.125\n",
      "MAE:  0.2182\n",
      "MSE:  0.2182\n",
      "RMSE:  0.4671\n"
     ]
    }
   ],
   "source": [
    "#Getting model metrics\n",
    "import sklearn.metrics as metrics\n",
    "def regression_results(y_true, y_pred):\n",
    "\n",
    "    # Regression metrics\n",
    "    explained_variance = metrics.explained_variance_score(y_true, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    mean_absolute_error = metrics.mean_absolute_error(y_true, y_pred) \n",
    "    mse = metrics.mean_squared_error(y_true, y_pred) \n",
    "#    mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)\n",
    "    median_absolute_error = metrics.median_absolute_error(y_true, y_pred)\n",
    "    r2 = metrics.r2_score(y_true, y_pred)\n",
    "\n",
    "    print('Explained Variance: ', round(explained_variance, 4))\n",
    "    print('Accuracy: ', round(accuracy, 4))\n",
    "#    print('mean_squared_log_error: ', round(mean_squared_log_error,4))\n",
    "    print('R2: ', round(r2, 4))\n",
    "    print('MAE: ', round(mean_absolute_error, 4))\n",
    "    print('MSE: ', round(mse, 4))\n",
    "    print('RMSE: ', round(np.sqrt(mse), 4))\n",
    "\n",
    "regression_results(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb684f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>follower_diffrat</th>\n",
       "      <td>0.175869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following_diffrat</th>\n",
       "      <td>0.007712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed_diffrat</th>\n",
       "      <td>0.326049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <td>-0.322884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <td>0.098122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <td>0.045825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <td>0.077457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts_diffrat</th>\n",
       "      <td>-0.012025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <td>0.473578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <td>0.118984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf3_diffrat</th>\n",
       "      <td>-0.015142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "follower_diffrat      0.175869\n",
       "following_diffrat     0.007712\n",
       "listed_diffrat        0.326049\n",
       "ment_rec_diffrat     -0.322884\n",
       "rt_rec_diffrat        0.098122\n",
       "ment_sent_diffrat     0.045825\n",
       "rt_sent_diffrat       0.077457\n",
       "posts_diffrat        -0.012025\n",
       "nf1_diffrat           0.473578\n",
       "nf2_diffrat           0.118984\n",
       "nf3_diffrat          -0.015142"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the variable coefficients\n",
    "coeff_parameter = pd.DataFrame(model.coef_, X.columns, columns = ['Coefficient'])\n",
    "#coeff_parameter.to_csv('Linear.csv')\n",
    "coeff_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17a84d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Choice   R-squared:                       0.382\n",
      "Model:                            OLS   Adj. R-squared:                  0.380\n",
      "Method:                 Least Squares   F-statistic:                     246.3\n",
      "Date:                Sat, 12 Feb 2022   Prob (F-statistic):               0.00\n",
      "Time:                        16:27:48   Log-Likelihood:                -2135.2\n",
      "No. Observations:                4400   AIC:                             4294.\n",
      "Df Residuals:                    4388   BIC:                             4371.\n",
      "Df Model:                          11                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.0163      0.015      1.052      0.293      -0.014       0.047\n",
      "follower_diffrat      0.1759      0.041      4.335      0.000       0.096       0.255\n",
      "following_diffrat     0.0077      0.019      0.413      0.680      -0.029       0.044\n",
      "listed_diffrat        0.3260      0.040      8.175      0.000       0.248       0.404\n",
      "ment_rec_diffrat     -0.3229      0.152     -2.131      0.033      -0.620      -0.026\n",
      "rt_rec_diffrat        0.0981      0.049      2.006      0.045       0.002       0.194\n",
      "ment_sent_diffrat     0.0458      0.036      1.281      0.200      -0.024       0.116\n",
      "rt_sent_diffrat       0.0775      0.027      2.883      0.004       0.025       0.130\n",
      "posts_diffrat        -0.0120      0.033     -0.365      0.715      -0.077       0.053\n",
      "nf1_diffrat           0.4736      0.153      3.085      0.002       0.173       0.774\n",
      "nf2_diffrat           0.1190      0.042      2.829      0.005       0.037       0.201\n",
      "nf3_diffrat          -0.0151      0.046     -0.329      0.742      -0.105       0.075\n",
      "==============================================================================\n",
      "Omnibus:                        9.783   Durbin-Watson:                   1.994\n",
      "Prob(Omnibus):                  0.008   Jarque-Bera (JB):                8.254\n",
      "Skew:                          -0.032   Prob(JB):                       0.0161\n",
      "Kurtosis:                       2.797   Cond. No.                         74.6\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Getting the model parameters\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_Sm = sm.add_constant(X_train)\n",
    "X_train_Sm = sm.add_constant(X_train)\n",
    "ls = sm.OLS(y_train,X_train_Sm).fit()\n",
    "print(ls.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39d83123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0...\n",
       "       9.46, 9.47, 9.48, 9.49, 9.5 , 9.51, 9.52, 9.53, 9.54, 9.55, 9.56,\n",
       "       9.57, 9.58, 9.59, 9.6 , 9.61, 9.62, 9.63, 9.64, 9.65, 9.66, 9.67,\n",
       "       9.68, 9.69, 9.7 , 9.71, 9.72, 9.73, 9.74, 9.75, 9.76, 9.77, 9.78,\n",
       "       9.79, 9.8 , 9.81, 9.82, 9.83, 9.84, 9.85, 9.86, 9.87, 9.88, 9.89,\n",
       "       9.9 , 9.91, 9.92, 9.93, 9.94, 9.95, 9.96, 9.97, 9.98, 9.99]),\n",
       "        cv=RepeatedKFold(n_repeats=25, n_splits=10, random_state=123),\n",
       "        n_alphas=10000, n_jobs=-1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lasso Regression\n",
    "\n",
    "#Importing the pckages\n",
    "from numpy import arange\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "#Define model evaluation method\n",
    "cv = RepeatedKFold(n_splits = 10, n_repeats = 25, random_state = 123)\n",
    "\n",
    "#Initialize model\n",
    "model2 = LassoCV(alphas = arange(0, 10, 0.01), n_alphas = 10000, cv = cv, n_jobs = -1)\n",
    "\n",
    "#Fitting the model\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8a8b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the test data using the model\n",
    "predictions2 = model2.predict(X_test)\n",
    "predictions2 = [round(num) for num in predictions2]\n",
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ba1ee2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  0.1272\n",
      "Accuracy:  0.7818\n",
      "R2:  0.125\n",
      "MAE:  0.2182\n",
      "MSE:  0.2182\n",
      "RMSE:  0.4671\n"
     ]
    }
   ],
   "source": [
    "#Getting model metrics\n",
    "regression_results(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1168ca8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>follower_diffrat</th>\n",
       "      <td>0.175870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following_diffrat</th>\n",
       "      <td>0.007711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed_diffrat</th>\n",
       "      <td>0.326050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <td>-0.322847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <td>0.098124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <td>0.045825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <td>0.077457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts_diffrat</th>\n",
       "      <td>-0.012026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <td>0.473539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <td>0.118986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf3_diffrat</th>\n",
       "      <td>-0.015143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "follower_diffrat      0.175870\n",
       "following_diffrat     0.007711\n",
       "listed_diffrat        0.326050\n",
       "ment_rec_diffrat     -0.322847\n",
       "rt_rec_diffrat        0.098124\n",
       "ment_sent_diffrat     0.045825\n",
       "rt_sent_diffrat       0.077457\n",
       "posts_diffrat        -0.012026\n",
       "nf1_diffrat           0.473539\n",
       "nf2_diffrat           0.118986\n",
       "nf3_diffrat          -0.015143"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the variable coefficients\n",
    "coeff_parameter2 = pd.DataFrame(model2.coef_, X.columns, columns = ['Coefficient'])\n",
    "#coeff_parameter2.to_csv('Lasso.csv')\n",
    "coeff_parameter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "039fb76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "       0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "       0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "       0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "       0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "       0.66, 0...\n",
       "       9.35, 9.36, 9.37, 9.38, 9.39, 9.4 , 9.41, 9.42, 9.43, 9.44, 9.45,\n",
       "       9.46, 9.47, 9.48, 9.49, 9.5 , 9.51, 9.52, 9.53, 9.54, 9.55, 9.56,\n",
       "       9.57, 9.58, 9.59, 9.6 , 9.61, 9.62, 9.63, 9.64, 9.65, 9.66, 9.67,\n",
       "       9.68, 9.69, 9.7 , 9.71, 9.72, 9.73, 9.74, 9.75, 9.76, 9.77, 9.78,\n",
       "       9.79, 9.8 , 9.81, 9.82, 9.83, 9.84, 9.85, 9.86, 9.87, 9.88, 9.89,\n",
       "       9.9 , 9.91, 9.92, 9.93, 9.94, 9.95, 9.96, 9.97, 9.98, 9.99]),\n",
       "        cv=RepeatedKFold(n_repeats=3, n_splits=10, random_state=1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "\n",
    "#Importing the packages\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "#Define model evaluation method\n",
    "cv = RepeatedKFold(n_splits = 10, n_repeats = 3, random_state = 1)\n",
    "\n",
    "#Initialize model\n",
    "model3 = RidgeCV(alphas = arange(0, 10, 0.01), cv = cv)\n",
    "\n",
    "#Fitting the model\n",
    "model3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c10e0be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the test data using the model\n",
    "predictions3 = model3.predict(X_test)\n",
    "predictions3 = [round(num) for num in predictions3]\n",
    "predictions3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3682a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  0.1276\n",
      "Accuracy:  0.7818\n",
      "R2:  0.125\n",
      "MAE:  0.2182\n",
      "MSE:  0.2182\n",
      "RMSE:  0.4671\n"
     ]
    }
   ],
   "source": [
    "#Getting model metrics\n",
    "regression_results(y_test, predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12e434b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>follower_diffrat</th>\n",
       "      <td>0.179434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following_diffrat</th>\n",
       "      <td>0.006170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed_diffrat</th>\n",
       "      <td>0.325999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <td>-0.189999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <td>0.096721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <td>0.045157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <td>0.077731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts_diffrat</th>\n",
       "      <td>-0.013387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <td>0.340455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <td>0.121223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf3_diffrat</th>\n",
       "      <td>-0.015162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "follower_diffrat      0.179434\n",
       "following_diffrat     0.006170\n",
       "listed_diffrat        0.325999\n",
       "ment_rec_diffrat     -0.189999\n",
       "rt_rec_diffrat        0.096721\n",
       "ment_sent_diffrat     0.045157\n",
       "rt_sent_diffrat       0.077731\n",
       "posts_diffrat        -0.013387\n",
       "nf1_diffrat           0.340455\n",
       "nf2_diffrat           0.121223\n",
       "nf3_diffrat          -0.015162"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the variable coefficients\n",
    "coeff_parameter3 = pd.DataFrame(model3.coef_, X.columns, columns = ['Coefficient'])\n",
    "#coeff_parameter3.to_csv('Ridge.csv')\n",
    "coeff_parameter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf3d5c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(cv=RepeatedKFold(n_repeats=50, n_splits=100, random_state=123),\n",
       "                     max_iter=1000, n_jobs=-1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "#Importing the pckages\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "#Define model evaluation method\n",
    "cv = RepeatedKFold(n_splits = 100, n_repeats = 50, random_state = 123)\n",
    "\n",
    "#Initialize model\n",
    "model4 = LogisticRegressionCV(cv = cv, max_iter = 1000, n_jobs = -1)\n",
    "\n",
    "#Fitting the model\n",
    "model4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fd6c033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting the test data using the model\n",
    "predictions4 = model4.predict(X_test)\n",
    "#predictions3 = [round(num) for num in predictions3]\n",
    "predictions4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e2c6448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance:  0.0924\n",
      "Accuracy:  0.7727\n",
      "R2:  0.0885\n",
      "MAE:  0.2273\n",
      "MSE:  0.2273\n",
      "RMSE:  0.4767\n"
     ]
    }
   ],
   "source": [
    "#Getting model metrics\n",
    "regression_results(y_test, predictions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e4f779e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>follower_diffrat</th>\n",
       "      <td>0.930204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following_diffrat</th>\n",
       "      <td>0.105017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>listed_diffrat</th>\n",
       "      <td>1.231369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_rec_diffrat</th>\n",
       "      <td>0.363081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_rec_diffrat</th>\n",
       "      <td>0.498584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ment_sent_diffrat</th>\n",
       "      <td>0.242079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rt_sent_diffrat</th>\n",
       "      <td>0.384380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>posts_diffrat</th>\n",
       "      <td>0.031637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf1_diffrat</th>\n",
       "      <td>0.511856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf2_diffrat</th>\n",
       "      <td>0.515437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf3_diffrat</th>\n",
       "      <td>0.247096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coefficient\n",
       "follower_diffrat      0.930204\n",
       "following_diffrat     0.105017\n",
       "listed_diffrat        1.231369\n",
       "ment_rec_diffrat      0.363081\n",
       "rt_rec_diffrat        0.498584\n",
       "ment_sent_diffrat     0.242079\n",
       "rt_sent_diffrat       0.384380\n",
       "posts_diffrat         0.031637\n",
       "nf1_diffrat           0.511856\n",
       "nf2_diffrat           0.515437\n",
       "nf3_diffrat           0.247096"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the variable coefficients\n",
    "coeff_parameter4 = pd.DataFrame(model4.coef_.transpose(), X.columns, columns = ['Coefficient'])\n",
    "#coeff_parameter4.to_csv('Log.csv')\n",
    "coeff_parameter4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7108bb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Profit with model: 9451173.609500041\n"
     ]
    }
   ],
   "source": [
    "#Predicting the lift\n",
    "#With model\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "y_choice = model4.predict(X)\n",
    "y_choice = [round(num) for num in y_choice]\n",
    "df['Choice'] = y_choice\n",
    "\n",
    "cost = 0\n",
    "rev = 0\n",
    "for row in range(len(df)):\n",
    "    cost += 10\n",
    "    if df.loc[row,'Choice'] == 1:\n",
    "        rev += df.loc[row,'A_follower_count'] * 10 * 0.00015\n",
    "    else:\n",
    "        rev += df.loc[row,'B_follower_count'] * 10 * 0.00015\n",
    "\n",
    "profit = rev - cost\n",
    "print('Net Profit with model:', profit) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2fbdce6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Profit without model: 5349068.592999984\n"
     ]
    }
   ],
   "source": [
    "#Without model\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "cost = 0\n",
    "rev = 0\n",
    "for row in range(len(df)):\n",
    "    cost += 5\n",
    "    if df.loc[row,'Choice'] == 1:\n",
    "        rev += df.loc[row,'A_follower_count'] * 10 * 0.0001\n",
    "    else:\n",
    "        rev += df.loc[row,'B_follower_count'] * 10 * 0.0001\n",
    "\n",
    "profit = rev - cost\n",
    "print('Net Profit without model:', profit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b44c160f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Lift Curve'}, xlabel='Percentage of sample', ylabel='Lift'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predicting the probability and plotting lift\n",
    "predictions = model4.predict_proba(X)\n",
    "\n",
    "import scikitplot as skplt\n",
    "skplt.metrics.plot_lift_curve(y, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
